this section focuses on the **analysis of algorithms**
	primarily in terms of predicting resources they require
		such a computational resources, time, memory, and energy consumption
			the RAM model is used for analyzing algorithms
				... instructions and data accesses are assumed to take constant time
					... regardless of what the instr or data operation is

**RAM Model assumption:**
	each instr takes the same amount of time
		data accesses like storing and retrieving values also take constant time
	the model assumes integer, floating-point, and character data types
	the precision of floating-point values is not usually a concern for this analysis
		...but it's important in other applicaitons
	the memory hierarchy is not considered in this model even though it can be
		...significant in real systems
		
**why analyze algorithms:**
	instead of running an algo and measuring execution time which depends on many
		...many factors such as hardware and bg tasks
			... algorithm analysis aims to determine the time complexity as a function of
				...input size
					this allows for prediction of performance across  various inputs
						... machines and other implementations
						
**insertion sort analysis**
	the analysis focuses on counting the number of times each line
		...in the algo is executed and the time it takes to exec them
	for example in the case of insert sort each iter of the outer loop executes
		a number of comparisons and data shifts depending on how sorted the array is
	the total run time is calculated by multiplying the cost of each statement by the number
		of times that it executes and taking all of those values and summing them together
			...in other words a sum of the loops costs all together
			
by breaking down the execution of each line of the algorithm we can derive an overall
	running time for the algorithm in terms of the input size n
		this analysis helps in understanding how the algo will scale with larger inputs and
			allows comparison with other algorithms for the same problem

	this does work for speeding this up
		this does not work for articulating more precise points in the book
			like formulas and pseduo-code examples as they will be skipped
				either due to latex encoding or for brevity
	to increase the quality of output for the summaries select informational
		and provide screenshots of the figures to the model

	trying that below
		also if images of figures are provided just screen shot them into
			...this compendium of notes

**insertion sort pseudocode --> rust**

```rust
fn insertion_sort(arr: &mut [i32]) {
    let n = arr.len();
    for i in 1..n {
        let key = arr[i];
        let mut j = i as isize - 1;

        // Insert arr[i] into the sorted subarray arr[0..i]
        while j >= 0 && arr[j as usize] > key {
            arr[(j + 1) as usize] = arr[j as usize];
            j -= 1;
        }
        arr[(j + 1) as usize] = key;
    }
}

```

**worst-case of insertion sort**

![[Pasted image 20241117091706.png]]

	when providing images to the gpt models it's helpful to indicate
		...what the image is actually in relation to
			...otherwise it does it's best on an assumption
	the best result so far with gemini in particular was:
		'explain the formula described by the following pseudocode'
			...then the pseudocode pasted
			...then a screenshot of the formula pasted
				additionally it seems to understand LaTeX 2e encoding
					when provided a copy pasted block of LaTeX
						...that represents a formula it still worked!
**formula**

	T(n) = c1​n + c2​(n−1) + c4​(n−1) + c5​i=2∑n​ti + c6​i=2∑n​(ti​−1) + c7​(ti​−1) + c8(n−1)
	
**breakdown**

c1n
	is a term representing the cost of the initial loop of the function
c2(n-1)
	accounts for the cost of comparing each element with the elements
c4(n-1)
	this term accounts for the init of the inner loop index j
c5 * Σ(t_i)
	this term accounts for the cost of the inner loop's
		...condition check which is executed variable # of times
			... t_i for each outer loop iteration i
				...summing up these costs over all i from 2 to n
c6 * Σ(t_i - 1)
	this term accounts for the sum of the cost of t_i - 1 times that
		... is done for each outer loop iteration
c7 * Σ(t_i -1)
	same
c8 * (n-1)
	this term accounts for the final placement of the key
		...which is done n-1 number of times
			
**key information**
	the exact value of t_i depends on the array input, and the specific iteration of i
		in the worst case when the array in in reverse order t_i is equal to i-1
			in the best case t_i is 1 for all values of i
			
**overall time complexity**
	the worse case complexity is O(n^2) which occurs when the input is in reverse
		...and in in the best case possible it's O(n)
			...the average time complexity is also O(n^2)
			
	so in my experiments with the gpt I've learned
		a: you can provide LaTeX 2e to chatgpt and other models and it can work
			with it
		b: pseudocode conversions to other languages is fine even when it's
			provided in latex form - chatgpt and others all do a good enough
				job at this
		c: gemini does a better job at handling image interpretation without
			complaining for whatever reason
		d: claude is the best so far at handling things, but is prohibitive
			...in terms of free usage by comparison to the others